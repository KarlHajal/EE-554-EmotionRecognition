{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import opensmile\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M09 Emotion Recognition exercise \n",
    "These two notebooks are guiding you through a simple emotion recognition script on the german EmoDB database.\n",
    "First of all, let's download the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavfolder = Path('wav')\n",
    "\n",
    "if not wavfolder.is_dir():\n",
    "    ! wget http://www.emodb.bilderbar.info/download/download.zip\n",
    "    ! unzip download.zip \"wav/*\"\n",
    "    Path(\"download.zip\").unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. Feature Extraction\n",
    "We start by extracting features using the openSMILE Python package. https://github.com/audeering/opensmile-python\n",
    "( There also exists a C++ library, that is a bit less convenient to use https://github.com/audeering/opensmile)\n",
    "\n",
    "However, classifying openSMILE features is a very popular baseline system, since it lets you extract a pre-defined set of features that work on most tasks. Generally, we distinguish two kinds of features:\n",
    "1) frame-level acoustic features \n",
    "2) utterance-level functionals (statistics) of acoustic features\n",
    "Since  paralinguistic tasks are not about modeling sequences, it is more convenient to just obtain one feature-vector per utterance and classify that. \n",
    "\n",
    "In this exercise we will extract utterance-level [eGeMAPS features](https://sail.usc.edu/publications/files/eyben-preprinttaffc-2015.pdf) from EmoDB and classify them in part 2 of the exercise. \n",
    "Make sure you pip-install all the imports, especially opensmile (e.g. <b>pip install opensmile</b>)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION\n",
    "labelfile = 'emodb_labels.csv'\n",
    "if not Path(labelfile).is_file():\n",
    "    print(f\"ERROR: Please upload the file {labelfile} to this folder.\")\n",
    "classtype = '\"{Anger,Boredom,Disgust,Fear,Happiness,Neutral,Sadness}\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDs of speakers used for training set\n",
    "indexes_train = ['11','12','13','14','15','16'] \n",
    "\n",
    "# IDs of speakers used for training set\n",
    "indexes_test = ['03','08','09','10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Creating an openSMILE object: \n",
    "Notice we're setting the feature set to be eGeMAPS\n",
    "and the feature-level to be functionals\n",
    "'''\n",
    "smile = opensmile.Smile(feature_set=opensmile.FeatureSet.eGeMAPSv01b,\n",
    "                        feature_level=opensmile.FeatureLevel.Functionals,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = []\n",
    "train_labels = []\n",
    "\n",
    "test_files = []\n",
    "test_labels = []\n",
    "\n",
    "with open(labelfile) as filelist:\n",
    "    for line in filelist:\n",
    "        instance, label = line.strip().split(\",\")\n",
    "        filename = wavfolder / instance\n",
    "\n",
    "        if instance[:2] in indexes_train:\n",
    "            train_files.append(filename)\n",
    "            train_labels.append(label)\n",
    "        elif instance[:2] in indexes_test:\n",
    "            test_files.append(filename)\n",
    "            test_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract OpenSMILE features. Takes a few minutes.\n",
    "train_df = smile.process_files(train_files)\n",
    "test_df = smile.process_files(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the class labels to the dataframe\n",
    "train_df[\"class\"] = train_labels\n",
    "test_df[\"class\"] = test_labels\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the results should be (347,89), meaning 347 instances, with 89 attributes\n",
    "# (88 eGeMAPS features and 1 label for each instance)\n",
    "print(f\"Instances: {train_df.shape[0]}, eGeMAPS-features and label: {train_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check balance of instances per class\n",
    "labels, counts = np.unique(train_df.values[:,-1], return_counts=True)\n",
    "# difference of instances\n",
    "len_diffs = counts - max(counts)\n",
    "print(\"Labels:\")\n",
    "print (labels)\n",
    "print(\"counts per class:\")\n",
    "print (counts)\n",
    "print(\"Differences of instances:\")\n",
    "print (len_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Numpy arrays\n",
    "train_data = train_df.values\n",
    "test_data = test_df.values\n",
    "\n",
    "# equalize the number instances across classes for better performance\n",
    "# (try later the effect when switching it on)\n",
    "balance_counts = False\n",
    "if balance_counts:    \n",
    "    for diff, label in zip(len_diffs, labels):\n",
    "        indices = np.where(train_data==label)[0]\n",
    "        for i in range(abs(diff)):\n",
    "            train_data = np.append(train_data,[train_data[np.random.choice(indices),:]],axis=0)\n",
    "        \n",
    "labels, counts = np.unique(train_data[:,-1], return_counts=True)\n",
    "print(\"New counts per class:\")\n",
    "print (counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all features information of the dataset, i.e., all content except the last column\n",
    "train_features = train_data[:,0:-1].astype(np.float32)\n",
    "\n",
    "# extract all labels information, i.e., the last column\n",
    "train_labels = train_data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set SVM classifier with linear kernel, for more details about svm and parameter settings, see\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n",
    "clf = svm.SVC(kernel='linear', C=0.01) \n",
    "\n",
    "# split data into 10 smaller sets and use 10-fold cross validation on the estimator and the data,\n",
    "# then generate predictions for all data, for more details see\n",
    "# http://scikit-learn.org/stable/modules/cross_validation.html\n",
    "predicted = cross_val_predict(clf, train_features, train_labels, cv=10)\n",
    "\n",
    "# print the predictions\n",
    "# print (predicted) \n",
    "\n",
    "print (\"Detailed classification report:\")\n",
    "print (\"\")\n",
    "\n",
    "# build a text report showing the main classification metrics.\n",
    "print (classification_report(train_labels, predicted)) \n",
    "\n",
    "print (\"confusion matrix, without normalisation:\")\n",
    "print (\"\")\n",
    "\n",
    "# compute the confusion matrix to evaluate the accuracy\n",
    "conf = confusion_matrix(train_labels, predicted)\n",
    "# visual representation of the confusion matrix\n",
    "fig, ax = plot_confusion_matrix(conf_mat=conf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run SVM with various kernels and check out the different results\n",
    "\n",
    "for c_kernel in ['linear', 'rbf', 'poly', 'sigmoid']:\n",
    "    clf = svm.SVC(kernel=c_kernel, C=0.1, gamma=\"scale\")\n",
    "    predicted = cross_val_predict(clf, train_features, train_labels, cv=10) \n",
    "    print (\"Detailed classification report with {}-kernel SVM:\".format(c_kernel))\n",
    "    print (\"\")\n",
    "    print (classification_report(train_labels, predicted))\n",
    "    print (\"confusion matrix with {}-kernel SVM, without normalisation:\".format(c_kernel))\n",
    "    print (\"\")\n",
    "    conf = confusion_matrix(train_labels, predicted)\n",
    "    # visual representation of the confusion matrix\n",
    "    fig, ax = plot_confusion_matrix(conf_mat=conf)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run SVM with different complexity values and check out the different results\n",
    "\n",
    "for c_value in [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]:\n",
    "    clf = svm.SVC(kernel='linear', C=c_value)\n",
    "    predicted = cross_val_predict(clf, train_features, train_labels, cv=10) \n",
    "    print (\"Detailed classification report when C={}:\".format(c_value))\n",
    "    print (\"\")\n",
    "    print (classification_report(train_labels, predicted))\n",
    "    print (\"confusion matrix when C={}, without normalisation:\".format(c_value))\n",
    "    print (\"\")\n",
    "    conf = confusion_matrix(train_labels, predicted)\n",
    "    # visual representation of the confusion matrix\n",
    "    fig, ax = plot_confusion_matrix(conf_mat=conf)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the results should be (188,89), meaning 188 instances, with 89 attributes \n",
    "# (88 eGeMAPS features and 1 label for each instance)\n",
    "print(test_data.shape)\n",
    "\n",
    "# extract all features information of the dataset, i.e., all content except the last column\n",
    "test_features = test_data[:,0:-1].astype(np.float32)\n",
    "\n",
    "# extract all labels information, i.e., the last column\n",
    "test_labels = test_data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test stage 2: choose the parameters which lead to the best result during cross validation \n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=0.01)\n",
    "\n",
    "# fit the best model on training data\n",
    "clf.fit(train_features, train_labels)\n",
    "predicted_test = clf.predict(test_features)\n",
    "\n",
    "# print the predictions\n",
    "# print (predicted)\n",
    "\n",
    "print (\"Detailed classification report on test data:\")\n",
    "print (\"\")\n",
    "\n",
    "# build a text report showing the main classification metrics.\n",
    "print (classification_report(test_labels, predicted_test))\n",
    "\n",
    "print (\"confusion matrix, without normalisation on test data:\")\n",
    "\n",
    "# compute the confusion matrix to evaluate the accuracy\n",
    "conf = confusion_matrix(test_labels, predicted_test)\n",
    "# visual representation of the confusion matrix\n",
    "fig, ax = plot_confusion_matrix(conf_mat=conf)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
